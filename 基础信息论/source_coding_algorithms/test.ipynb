{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "with open('chinese_text.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "# print(content)\n",
    "counter = Counter(content)\n",
    "total = sum(counter.values()) # 总字数\n",
    "\n",
    "symbols = list(counter.keys()) # 字符\n",
    "probs = [counter[s] / total for s in symbols]\n",
    "\n",
    "def shannon_code(symbols, probs):\n",
    "    codes = {}\n",
    "    q = 0.0\n",
    "    \n",
    "    # sort the probabilities(large to small)\n",
    "    sorted_probs = sorted(zip(symbols, probs), key=lambda x:-x[1])\n",
    "    \n",
    "    for s, p in sorted_probs:\n",
    "        l = math.ceil(-math.log2(p)) # get optimal codeword length\n",
    "        code = ''\n",
    "        q_bin = q\n",
    "        # get binary\n",
    "        for _ in range(l):\n",
    "            q_bin *= 2\n",
    "            bit = int(q_bin)\n",
    "            code += str(bit)\n",
    "            q_bin -= bit\n",
    "        codes[s] = code\n",
    "        q += p\n",
    "    return codes\n",
    "\n",
    "codes = shannon_code(symbols, probs)\n",
    "\n",
    "for s in symbols:\n",
    "    if s == '\\n':\n",
    "        display_s = '\\\\n'\n",
    "    elif s == ' ':\n",
    "        display_s = \"' '\"\n",
    "    else:\n",
    "        display_s = s\n",
    "    print(f\"symbol: {display_s} code: {codes[s]}\")\n",
    "    \n",
    "# 计算信源熵\n",
    "entropy = -sum(p * math.log2(p) for p in probs)\n",
    "\n",
    "# 计算平均码长\n",
    "avg_code_len = sum([len(codes[s]) * probs[i] for i, s in enumerate(symbols)])\n",
    "\n",
    "# 计算编码效率\n",
    "efficiency = entropy / avg_code_len if avg_code_len > 0 else 0\n",
    "\n",
    "print(f\"\\ninfo source entropy: {entropy:.4f}\")\n",
    "print(f\"avg. codeword length: {avg_code_len:.4f}\")\n",
    "print(f\"encoding efficiency: {efficiency:.4f}\")\n",
    "\n",
    "# 编码整个文本\n",
    "encoded_text = ''.join([codes[c] for c in content])\n",
    "# print(encoded_text)\n",
    "\n",
    "# 构建解码映射\n",
    "decode_map = {v: k for k, v in codes.items()}\n",
    "\n",
    "# 解码函数\n",
    "def shannon_decode(encoded_str, decode_map):\n",
    "    decoded = []\n",
    "    buffer = ''\n",
    "    max_code_len = max(len(code) for code in decode_map)\n",
    "    i = 0\n",
    "    while i < len(encoded_str):\n",
    "        buffer = ''\n",
    "        for l in range(1, max_code_len + 1):\n",
    "            if i + l > len(encoded_str):\n",
    "                break\n",
    "            buffer = encoded_str[i:i+l]\n",
    "            if buffer in decode_map:\n",
    "                decoded.append(decode_map[buffer])\n",
    "                i += l\n",
    "                break\n",
    "        else:\n",
    "            # 没有匹配到，跳出\n",
    "            break\n",
    "    return ''.join(decoded)\n",
    "\n",
    "# 解码并计时\n",
    "start_time = time.time()\n",
    "decoded_text = shannon_decode(encoded_text, decode_map)\n",
    "end_time = time.time()\n",
    "\n",
    "with open('decoded_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(decoded_text)\n",
    "\n",
    "print(f\"\\nwhether decoding is correct: {decoded_text == content}\")\n",
    "print(f\"decoding time : {end_time - start_time:.6f} seconds\")\n",
    "print(\"\\ndecoded text: \")\n",
    "print(decoded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edwardpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
